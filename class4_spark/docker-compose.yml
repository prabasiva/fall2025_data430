services:
  spark-master:
    image: apache/spark:3.5.0
    container_name: spark-master
    hostname: spark-master
    user: root
    ports:
      - "8080:8080"  # Spark Master Web UI
      - "7077:7077"  # Spark Master Port
      - "4040:4040"  # Spark Application UI (when running)
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
      - SPARK_DAEMON_MEMORY=1g
    volumes:
      - ./data:/data
      - ./apps:/apps
      - spark-logs:/opt/spark/logs
    networks:
      - spark-network
    command: >
      bash -c "
        chmod -R 777 /opt/spark/logs &&
        /opt/spark/sbin/start-master.sh &&
        tail -f /opt/spark/logs/spark--org.apache.spark.deploy.master.Master-*.out
      "
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  spark-worker-1:
    image: apache/spark:3.5.0
    container_name: spark-worker-1
    hostname: spark-worker-1
    user: root
    depends_on:
      spark-master:
        condition: service_healthy
    ports:
      - "8081:8081"  # Worker 1 Web UI
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_WEBUI_PORT=8081
      - SPARK_WORKER_PORT=7078
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2g
      - SPARK_DAEMON_MEMORY=1g
    volumes:
      - ./data:/data
      - ./apps:/apps
      - spark-logs:/opt/spark/logs
    networks:
      - spark-network
    command: >
      bash -c "
        chmod -R 777 /opt/spark/logs &&
        /opt/spark/sbin/start-worker.sh spark://spark-master:7077 &&
        tail -f /opt/spark/logs/spark--org.apache.spark.deploy.worker.Worker-*.out
      "
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  spark-worker-2:
    image: apache/spark:3.5.0
    container_name: spark-worker-2
    hostname: spark-worker-2
    user: root
    depends_on:
      spark-master:
        condition: service_healthy
    ports:
      - "8082:8082"  # Worker 2 Web UI
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_WEBUI_PORT=8082
      - SPARK_WORKER_PORT=7079
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2g
      - SPARK_DAEMON_MEMORY=1g
    volumes:
      - ./data:/data
      - ./apps:/apps
      - spark-logs:/opt/spark/logs
    networks:
      - spark-network
    command: >
      bash -c "
        chmod -R 777 /opt/spark/logs &&
        /opt/spark/sbin/start-worker.sh spark://spark-master:7077 &&
        tail -f /opt/spark/logs/spark--org.apache.spark.deploy.worker.Worker-*.out
      "
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8082"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Optional: Spark History Server
  spark-history:
    image: apache/spark:3.5.0
    container_name: spark-history
    hostname: spark-history
    user: root
    depends_on:
      - spark-master
    ports:
      - "18080:18080"  # History Server Web UI
    environment:
      - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=/tmp/spark-events
      - SPARK_DAEMON_MEMORY=1g
    volumes:
      - spark-events:/tmp/spark-events
      - spark-logs:/opt/spark/logs
    networks:
      - spark-network
    command: >
      bash -c "
        chmod -R 777 /opt/spark/logs &&
        mkdir -p /tmp/spark-events &&
        /opt/spark/sbin/start-history-server.sh &&
        tail -f /opt/spark/logs/spark--org.apache.spark.deploy.history.HistoryServer-*.out
      "

networks:
  spark-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16

volumes:
  spark-logs:
  spark-events:

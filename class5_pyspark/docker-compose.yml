services:
  spark-master:
    image: apache/spark-py:latest
    container_name: pyspark-master
    hostname: spark-master
    user: root
    ports:
      - "8080:8080"  # Spark Master Web UI
      - "7077:7077"  # Spark Master Port
      - "4090:4040"  # Spark Application UI
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
    volumes:
      - ./data:/data
      - ./apps:/apps
      - ./notebooks:/notebooks
      - spark-logs:/opt/spark/logs
    networks:
      - spark-network
    command: >
      bash -c "
        chmod -R 777 /opt/spark/logs &&
        /opt/spark/sbin/start-master.sh &&
        tail -f /opt/spark/logs/spark--org.apache.spark.deploy.master.Master-*.out
      "
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  spark-worker-1:
    image: apache/spark-py:latest
    container_name: pyspark-worker-1
    hostname: spark-worker-1
    user: root
    depends_on:
      spark-master:
        condition: service_healthy
    ports:
      - "8081:8081"  # Worker 1 Web UI
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_WEBUI_PORT=8081
      - SPARK_WORKER_PORT=7078
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2g
    volumes:
      - ./data:/data
      - ./apps:/apps
      - ./notebooks:/notebooks
      - spark-logs:/opt/spark/logs
    networks:
      - spark-network
    command: >
      bash -c "
        chmod -R 777 /opt/spark/logs &&
        /opt/spark/sbin/start-worker.sh spark://spark-master:7077 &&
        tail -f /opt/spark/logs/spark--org.apache.spark.deploy.worker.Worker-*.out
      "
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  spark-worker-2:
    image: apache/spark-py:latest
    container_name: pyspark-worker-2
    hostname: spark-worker-2
    user: root
    depends_on:
      spark-master:
        condition: service_healthy
    ports:
      - "8082:8082"  # Worker 2 Web UI
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_WEBUI_PORT=8082
      - SPARK_WORKER_PORT=7079
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2g
    volumes:
      - ./data:/data
      - ./apps:/apps
      - ./notebooks:/notebooks
      - spark-logs:/opt/spark/logs
    networks:
      - spark-network
    command: >
      bash -c "
        chmod -R 777 /opt/spark/logs &&
        /opt/spark/sbin/start-worker.sh spark://spark-master:7077 &&
        tail -f /opt/spark/logs/spark--org.apache.spark.deploy.worker.Worker-*.out
      "
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8082"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  jupyter:
    image: apache/spark-py:latest
    container_name: pyspark-jupyter
    hostname: jupyter
    user: root
    depends_on:
      spark-master:
        condition: service_healthy
    ports:
      - "8888:8888"  # Jupyter Notebook
      - "4041:4041"  # Spark Application UI for Jupyter
      - "4040-4050:4040-4050"  # Driver ports for cluster mode
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_LOCAL_IP=jupyter
      - PYSPARK_DRIVER_PYTHON=jupyter
      - PYSPARK_DRIVER_PYTHON_OPTS=notebook
      - PYTHONPATH=/opt/spark/python:/opt/spark/python/lib/py4j-0.10.9.7-src.zip:$PYTHONPATH
      - SPARK_HOME=/opt/spark
    volumes:
      - ./notebooks:/notebooks
      - ./data:/data
      - ./apps:/apps
    networks:
      - spark-network
    working_dir: /notebooks
    command: >
      bash -c "
        pip install jupyter notebook jupyterlab &&
        jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser --allow-root --NotebookApp.token='' --NotebookApp.password=''
      "

  spark-history:
    image: apache/spark-py:latest
    container_name: pyspark-history
    hostname: spark-history
    user: root
    depends_on:
      - spark-master
    ports:
      - "18080:18080"  # History Server Web UI
    environment:
      - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=/tmp/spark-events
    volumes:
      - spark-events:/tmp/spark-events
      - spark-logs:/opt/spark/logs
    networks:
      - spark-network
    command: >
      bash -c "
        chmod -R 777 /opt/spark/logs &&
        mkdir -p /tmp/spark-events &&
        /opt/spark/sbin/start-history-server.sh &&
        tail -f /opt/spark/logs/spark--org.apache.spark.deploy.history.HistoryServer-*.out
      "

networks:
  spark-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.29.0.0/16

volumes:
  spark-events:
  spark-logs:
